{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def plot_decision_boundary_2d(model, X_2d, y, title=\"\", h=0.02):\n",
    "# #     \"\"\"\n",
    "# #     Visualize decision boundary for a 2D feature space.\n",
    "\n",
    "# #     X_2d: DataFrame or array with exactly 2 columns\n",
    "# #     y   : labels (Series or array)\n",
    "# #     \"\"\"\n",
    "# #     if isinstance(X_2d, pd.DataFrame):\n",
    "# #         X_vals = X_2d.values\n",
    "# #         feature_names = list(X_2d.columns)\n",
    "# #     else:\n",
    "# #         X_vals = X_2d\n",
    "# #         feature_names = [\"Feature 1\", \"Feature 2\"]\n",
    "\n",
    "# #     x_min, x_max = X_vals[:, 0].min() - 0.5, X_vals[:, 0].max() + 0.5\n",
    "# #     y_min, y_max = X_vals[:, 1].min() - 0.5, X_vals[:, 1].max() + 0.5\n",
    "\n",
    "# #     xx, yy = np.meshgrid(\n",
    "# #         np.arange(x_min, x_max, h),\n",
    "# #         np.arange(y_min, y_max, h)\n",
    "# #     )\n",
    "\n",
    "# #     grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "# #     Z = model.predict(grid)\n",
    "# #     Z = Z.reshape(xx.shape)\n",
    "\n",
    "# #     plt.figure(figsize=(7, 5))\n",
    "# #     plt.contourf(xx, yy, Z, alpha=0.3, cmap=\"tab10\")\n",
    "# #     scatter = plt.scatter(\n",
    "# #         X_vals[:, 0], X_vals[:, 1],\n",
    "# #         c=y, cmap=\"tab10\", s=10, edgecolor=\"k\", linewidth=0.1\n",
    "# #     )\n",
    "# #     plt.xlabel(feature_names[0])\n",
    "# #     plt.ylabel(feature_names[1])\n",
    "# #     plt.title(title)\n",
    "# #     plt.tight_layout()\n",
    "# #     plt.show()\n",
    "\n",
    "# from sklearn.base import clone\n",
    "\n",
    "# def plot_decision_boundary_2d(model, X_2d, y, title=\"\", h=0.02):\n",
    "#     \"\"\"\n",
    "#     Visualize decision boundary for a 2D feature space.\n",
    "\n",
    "#     model : 已经训练好的模型（在全特征上没关系）\n",
    "#     X_2d  : 只包含两个特征的 DataFrame 或 array\n",
    "#     y     : 标签\n",
    "#     \"\"\"\n",
    "#     # 克隆一个“同结构但未训练”的模型，只在 2D 特征上重新训练，用于画边界\n",
    "#     model_2d = clone(model)\n",
    "#     model_2d.fit(X_2d, y)\n",
    "\n",
    "#     if isinstance(X_2d, pd.DataFrame):\n",
    "#         X_vals = X_2d.values\n",
    "#         feature_names = list(X_2d.columns)\n",
    "#     else:\n",
    "#         X_vals = X_2d\n",
    "#         feature_names = [\"Feature 1\", \"Feature 2\"]\n",
    "\n",
    "#     x_min, x_max = X_vals[:, 0].min() - 0.5, X_vals[:, 0].max() + 0.5\n",
    "#     y_min, y_max = X_vals[:, 1].min() - 0.5, X_vals[:, 1].max() + 0.5\n",
    "\n",
    "#     xx, yy = np.meshgrid(\n",
    "#         np.arange(x_min, x_max, h),\n",
    "#         np.arange(y_min, y_max, h)\n",
    "#     )\n",
    "\n",
    "#     grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "#     # 用 2D 版本的模型预测\n",
    "#     Z = model_2d.predict(grid)\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "\n",
    "#     plt.figure(figsize=(7, 5))\n",
    "#     plt.contourf(xx, yy, Z, alpha=0.3, cmap=\"tab10\")\n",
    "#     plt.scatter(\n",
    "#         X_vals[:, 0], X_vals[:, 1],\n",
    "#         c=y, cmap=\"tab10\", s=10, edgecolor=\"k\", linewidth=0.1\n",
    "#     )\n",
    "#     plt.xlabel(feature_names[0])\n",
    "#     plt.ylabel(feature_names[1])\n",
    "#     plt.title(title)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# def evaluate_classifier(model, X_tr, y_tr, X_te, y_te, labels_sorted):\n",
    "#     # Train the model\n",
    "#     model.fit(X_tr, y_tr)\n",
    "\n",
    "#     # Construct entire set\n",
    "#     X_all = pd.concat([X_tr, X_te], axis=0)\n",
    "#     y_all = pd.concat([y_tr, y_te], axis=0)\n",
    "\n",
    "#     # Predictions for three splits\n",
    "#     y_pred_train = model.predict(X_tr)\n",
    "#     y_pred_test = model.predict(X_te)\n",
    "#     y_pred_all = model.predict(X_all)\n",
    "\n",
    "#     def report_split(y_true, y_pred, split_name):\n",
    "#         acc = accuracy_score(y_true, y_pred)\n",
    "#         prec = precision_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "#         rec = recall_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "#         f1 = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "#         print(f\"{split_name} — Acc: {acc:.4f}, Prec: {prec:.4f}, Rec: {rec:.4f}, F1: {f1:.4f}\")\n",
    "#         return {\n",
    "#             \"accuracy\": acc,\n",
    "#             \"precision\": prec,\n",
    "#             \"recall\": rec,\n",
    "#             \"f1\": f1\n",
    "#         }\n",
    "\n",
    "#     print(f\"\\n=== {model.__class__.__name__} ===\")\n",
    "#     metrics_train = report_split(y_tr, y_pred_train, \"Train\")\n",
    "#     metrics_test = report_split(y_te, y_pred_test, \"Test\")\n",
    "#     metrics_all = report_split(y_all, y_pred_all, \"All\")\n",
    "\n",
    "#     # Plot confusion matrix for all three splits\n",
    "#     for split_name, y_true, y_pred in [\n",
    "#         (\"Train\", y_tr, y_pred_train),\n",
    "#         (\"Test\", y_te, y_pred_test),\n",
    "#         (\"All\", y_all, y_pred_all),\n",
    "#     ]:\n",
    "#         cm = confusion_matrix(y_true, y_pred, labels=labels_sorted)\n",
    "#         plot_confusion(\n",
    "#             cm,\n",
    "#             labels_sorted,\n",
    "#             title=f\"{model.__class__.__name__} — {split_name} confusion matrix\"\n",
    "#         )\n",
    "\n",
    "#     # Return metrics for three splits\n",
    "#     return {\n",
    "#         \"train\": metrics_train,\n",
    "#         \"test\": metrics_test,\n",
    "#         \"all\": metrics_all\n",
    "#     }, model\n",
    "\n",
    "# labels_sorted = sorted(y.unique())\n",
    "\n",
    "# # Logistic Regression\n",
    "# log_reg = LogisticRegression(\n",
    "#     max_iter=200,\n",
    "#     multi_class=\"multinomial\",\n",
    "#     solver=\"lbfgs\",\n",
    "#     n_jobs=-1,\n",
    "#     random_state=RANDOM_STATE,\n",
    "#     class_weight=\"balanced\"\n",
    "# )\n",
    "# lr_metrics, log_reg_fitted = evaluate_classifier(\n",
    "#     log_reg, X_train_scaled, y_train, X_test_scaled, y_test, labels_sorted\n",
    "# )\n",
    "\n",
    "# # Random Forest\n",
    "# rf = RandomForestClassifier(\n",
    "#     n_estimators=200,\n",
    "#     max_depth=None,\n",
    "#     n_jobs=-1,\n",
    "#     random_state=RANDOM_STATE,\n",
    "#     class_weight=\"balanced\"\n",
    "# )\n",
    "# rf_metrics, rf_fitted = evaluate_classifier(\n",
    "#     rf, X_train_scaled, y_train, X_test_scaled, y_test, labels_sorted\n",
    "# )\n",
    "\n",
    "# # ====== Visualize decision boundaries on a 2D feature slice ======\n",
    "\n",
    "# feature_pair = [\"Elevation\", \"Slope\"]  # Can also choose any of the other two features.\n",
    "\n",
    "# X_train_2d = X_train_scaled[feature_pair]\n",
    "\n",
    "# print(\"\\nDecision boundary — Logistic Regression\")\n",
    "# plot_decision_boundary_2d(\n",
    "#     log_reg_fitted,\n",
    "#     X_train_2d,\n",
    "#     y_train,\n",
    "#     title=\"Logistic Regression — decision boundary (Elevation vs Slope)\"\n",
    "# )\n",
    "\n",
    "# print(\"\\nDecision boundary — Random Forest\")\n",
    "# plot_decision_boundary_2d(\n",
    "#     rf_fitted,\n",
    "#     X_train_2d,\n",
    "#     y_train,\n",
    "#     title=\"Random Forest — decision boundary (Elevation vs Slope)\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d639bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Visualization for feature selection, tuning, and model comparison\n",
    "# =========================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# ---------- 1. SelectKBest: ANOVA F-score 可视化 ----------\n",
    "\n",
    "selector = lr_fs.named_steps[\"select\"]\n",
    "scores = selector.scores_\n",
    "\n",
    "# 所有特征的 F-score\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(len(scores)), scores)\n",
    "plt.title(\"ANOVA F-values for all features\")\n",
    "plt.xlabel(\"Feature index\")\n",
    "plt.ylabel(\"F-score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top-k 特征的 F-score\n",
    "top_k_idx = np.argsort(scores)[-fs_k:]\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(range(fs_k), scores[top_k_idx])\n",
    "plt.title(f\"Top {fs_k} selected features by ANOVA F-score\")\n",
    "plt.xlabel(\"Selected feature rank (by score)\")\n",
    "plt.ylabel(\"F-score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---------- 2. Random Forest GridSearchCV 结果热力图 ----------\n",
    "\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "heatmap_data = cv_results.pivot_table(\n",
    "    values=\"mean_test_score\",\n",
    "    index=\"param_max_depth\",\n",
    "    columns=\"param_max_features\",\n",
    "    aggfunc=\"mean\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\".4f\", cmap=\"viridis\")\n",
    "plt.title(\"Random Forest GridSearchCV — Mean CV Accuracy\")\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.ylabel(\"max_depth\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---------- 3. 不同模型的 3-fold CV accuracy 对比 ----------\n",
    "\n",
    "cv_summary = []\n",
    "for name, model in cv_models.items():\n",
    "    scores = cross_val_score(model, X_cv, y_cv, cv=3,\n",
    "                             scoring=\"accuracy\", n_jobs=-1)\n",
    "    cv_summary.append({\n",
    "        \"Model\": name,\n",
    "        \"MeanAcc\": scores.mean(),\n",
    "        \"StdAcc\": scores.std()\n",
    "    })\n",
    "\n",
    "cv_df = pd.DataFrame(cv_summary)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(data=cv_df, x=\"Model\", y=\"MeanAcc\")\n",
    "plt.errorbar(\n",
    "    x=range(len(cv_df)),\n",
    "    y=cv_df[\"MeanAcc\"],\n",
    "    yerr=cv_df[\"StdAcc\"],\n",
    "    fmt=\"none\", ecolor=\"black\", capsize=4\n",
    ")\n",
    "plt.title(\"3-fold CV Accuracy on 20k Subset\")\n",
    "plt.ylabel(\"Mean CV Accuracy\")\n",
    "plt.xticks(rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---------- 4. 各模型 Test accuracy 对比 ----------\n",
    "\n",
    "test_scores = {\n",
    "    \"SelectKBest + LogReg\": fs_acc,\n",
    "    \"GradientBoosting\": gb_acc,\n",
    "    \"HistGradientBoosting\": hgb_acc,\n",
    "    \"Best RandomForest\": best_rf_test_acc,\n",
    "    \"LinearSVM (30k)\": svm_test_acc\n",
    "}\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    \"Model\": list(test_scores.keys()),\n",
    "    \"TestAcc\": list(test_scores.values())\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(data=test_df, x=\"Model\", y=\"TestAcc\")\n",
    "plt.title(\"Test Accuracy Comparison Across Models\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.xticks(rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
