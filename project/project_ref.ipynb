{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5edd7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap.umap_ as umap\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve, validation_curve\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    roc_curve, auc, roc_auc_score,\n",
    "    adjusted_rand_score, normalized_mutual_info_score,\n",
    "    fowlkes_mallows_score, silhouette_score,\n",
    "    calinski_harabasz_score, davies_bouldin_score\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89552977",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a0e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\n",
    "    r\"D:\\\\Coding\\\\DSAA2011_project\\\\human+activity+recognition+using+smartphones\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\train\\\\X_train.txt\",\n",
    "    sep=r'\\s+', header=None)\n",
    "y_train = pd.read_csv(\n",
    "    r\"D:\\\\Coding\\\\DSAA2011_project\\\\human+activity+recognition+using+smartphones\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\train\\\\y_train.txt\",\n",
    "    sep=r'\\s+', header=None).squeeze()\n",
    "X_test = pd.read_csv(\n",
    "    r\"D:\\\\Coding\\\\DSAA2011_project\\\\human+activity+recognition+using+smartphones\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\test\\\\X_test.txt\",\n",
    "    sep=r'\\s+', header=None)\n",
    "y_test = pd.read_csv(\n",
    "    r\"D:\\\\Coding\\\\DSAA2011_project\\\\human+activity+recognition+using+smartphones\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\test\\\\y_test.txt\",\n",
    "    sep=r'\\s+', header=None).squeeze()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7481b88f",
   "metadata": {},
   "source": [
    "**Applied Methods:**\n",
    "We read the UCI HAR dataset and used StandardScaler to normalize the feature values so they are on the same scale.\n",
    "\n",
    "**Observed Patterns or Insights:**\n",
    "The dataset has 561 continuous features and clear labels. There are no missing values, and the data is ready for further analysis like classification or clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6511d1",
   "metadata": {},
   "source": [
    "## 2. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093862b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"PCA\": PCA(n_components=2),\n",
    "    \"t-SNE\": TSNE(n_components=2, perplexity=30, random_state=42),\n",
    "    \"UMAP\": umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "for i, (name, model) in enumerate(methods.items()):\n",
    "    X_vis = model.fit_transform(X_train_scaled)\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.scatter(X_vis[:, 0], X_vis[:, 1], c=y_train, cmap='tab10', s=10)\n",
    "    plt.title(name)\n",
    "    plt.xlabel(\"Dim 1\")\n",
    "    plt.ylabel(\"Dim 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337ae02a",
   "metadata": {},
   "source": [
    "**Applied Methods:**\n",
    "We used StandardScaler to normalize the data, then applied PCA, t-SNE, and UMAP to reduce the data to 2D for visualization.\n",
    "\n",
    "**Observed Patterns or Insights:**\n",
    "PCA results were scattered with no clear clusters. t-SNE showed clear groupings by label. UMAP also formed tight clusters and kept some global structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a1988d",
   "metadata": {},
   "source": [
    "## 3. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c9c99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = {\n",
    "    'KMeans': KMeans(n_clusters=6, random_state=42),\n",
    "    'GMM': GaussianMixture(n_components=6, random_state=42),\n",
    "    'Agglomerative': AgglomerativeClustering(n_clusters=6, linkage='ward'),\n",
    "    'DBSCAN': DBSCAN(eps=0.5, min_samples=3)\n",
    "}\n",
    "\n",
    "def purity_score(y_train, y_pred):\n",
    "    matrix = confusion_matrix(y_train, y_pred)\n",
    "    return np.sum(np.max(matrix, axis=0)) / np.sum(matrix)\n",
    "\n",
    "def evaluate_clustering(y_train, X_train, labels):\n",
    "    valid = len(set(labels)) > 1 and -1 not in set(labels)\n",
    "    return {\n",
    "        'ARI': adjusted_rand_score(y_train, labels),\n",
    "        'NMI': normalized_mutual_info_score(y_train, labels),\n",
    "        'FMI': fowlkes_mallows_score(y_train, labels),\n",
    "        'Purity': purity_score(y_train, labels),\n",
    "        'Silhouette': silhouette_score(X_train, labels) if valid else np.nan,\n",
    "        'CH': calinski_harabasz_score(X_train, labels) if valid else np.nan,\n",
    "        'DBI': davies_bouldin_score(X_train, labels) if valid else np.nan,\n",
    "    }\n",
    "\n",
    "results = {}\n",
    "cluster_labels = {}\n",
    "\n",
    "for name, algo in algorithms.items():\n",
    "    print(f\"Clustering with {name}...\")\n",
    "    if name == 'GMM':\n",
    "        labels = algo.fit_predict(X_train)\n",
    "    else:\n",
    "        labels = algo.fit(X_train).labels_ if hasattr(algo, 'fit_predict') else algo.fit_predict(X_train)\n",
    "    cluster_labels[name] = labels\n",
    "    results[name] = evaluate_clustering(y_train, X_train, labels)\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\n=== Clustering Evaluation Results ===\")\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv(\"clustering_evaluation_summary.csv\")\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=40, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_train)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (name, labels) in enumerate(cluster_labels.items()):\n",
    "    axes[i].scatter(X_tsne[:, 0], X_tsne[:, 1], c=labels, cmap='tab10', s=10)\n",
    "    axes[i].set_title(f\"{name} Clustering\")\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "external_scores = results_df[['ARI', 'NMI', 'FMI', 'Purity']].mean(axis=1)\n",
    "top2 = external_scores.sort_values(ascending=False).head(2).index.tolist()\n",
    "print(f\"Top 2 clustering methods selected for ensemble: {top2}\")\n",
    "\n",
    "ensemble_features = np.vstack([\n",
    "    cluster_labels[top2[0]],\n",
    "    cluster_labels[top2[1]]\n",
    "]).T\n",
    "\n",
    "ensemble_kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "ensemble_labels = ensemble_kmeans.fit_predict(ensemble_features)\n",
    "\n",
    "cluster_labels['Ensemble'] = ensemble_labels\n",
    "results['Ensemble'] = evaluate_clustering(y_train, X_train, ensemble_labels)\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\n=== Updated Clustering Evaluation Results (with Ensemble) ===\")\n",
    "print(results_df)\n",
    "results_df.to_csv(\"clustering_evaluation_with_ensemble.csv\")\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y_train, cmap='tab10', s=10)\n",
    "plt.title(\"Ground Truth Labels\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=ensemble_labels, cmap='tab10', s=10)\n",
    "plt.title(\"Ensemble Clustering\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8272fd5",
   "metadata": {},
   "source": [
    "### Clustering Methods\n",
    "\n",
    "- **K-Means**: Fast and simple; works well for spherical clusters; commonly used as a baseline.  \n",
    "- **GMM**: Probabilistic model; supports soft clustering; good for overlapping clusters.  \n",
    "- **Agglomerative Clustering**: Hierarchical approach; captures structure; doesn’t rely on initial centroids.  \n",
    "- **DBSCAN**: Density-based; no need to set cluster number; can detect noise.\n",
    "\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "**External Metrics**:\n",
    "\n",
    "- **ARI**: Adjusted similarity to ground truth.  \n",
    "- **NMI**: Measures shared information.  \n",
    "- **FMI**, **Purity**: Accuracy and cluster purity.\n",
    "\n",
    "**Internal Metrics**:\n",
    "\n",
    "- **Silhouette Score**: Cluster separation and cohesion.  \n",
    "- **Calinski-Harabasz Index (CH)**: Ratio of between- to within-cluster variance.  \n",
    "- **Davies-Bouldin Index (DB)**: Cluster similarity (lower is better).\n",
    "\n",
    "\n",
    "### Results & Insights\n",
    "\n",
    "- **GMM**: Best performance overall; closely matches true labels.  \n",
    "- **K-Means**: Fast and stable; decent results, but weaker on internal metrics.  \n",
    "- **Agglomerative**: Moderate results; affected by high dimensionality.  \n",
    "- **DBSCAN**: Poor performance; struggled with structure and density variation.\n",
    "\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "**GMM** and **K-Means** are the most suitable clustering methods for this dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d651e9",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "- Logistic Regression \n",
    "- SVM\n",
    "- Random Forest \n",
    "\n",
    "The data is read separately in the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96613c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features\n",
    "X_train = np.loadtxt('train/X_train.txt')\n",
    "X_test = np.loadtxt('test/X_test.txt')\n",
    "\n",
    "y_train = np.loadtxt('train/y_train.txt').astype(int)\n",
    "y_test = np.loadtxt('test/y_test.txt').astype(int)\n",
    "\n",
    "# Train logistic regression model\n",
    "clf = LogisticRegression(max_iter=200, solver='lbfgs', multi_class='multinomial')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "# Calculate performance metrics for training set and test set\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Logistic Regression Train Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Logistic Regression Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Precision\n",
    "train_precision = precision_score(y_train, y_pred_train, average='weighted')\n",
    "test_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f'Logistic Regression Train Precision: {train_precision:.4f}')\n",
    "print(f'Logistic Regression Test Precision: {test_precision:.4f}')\n",
    "\n",
    "# Recall\n",
    "train_recall = recall_score(y_train, y_pred_train, average='weighted')\n",
    "test_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print(f'Logistic Regression Train Recall: {train_recall:.4f}')\n",
    "print(f'Logistic Regression Test Recall: {test_recall:.4f}')\n",
    "\n",
    "# F1\n",
    "train_f1 = f1_score(y_train, y_pred_train, average='weighted')\n",
    "test_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'Logistic Regression Train F1 Score: {train_f1:.4f}')\n",
    "print(f'Logistic Regression Test F1 Score: {test_f1:.4f}')\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualize performance metrics\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "train_scores = [train_accuracy, train_precision, train_recall, train_f1]\n",
    "test_scores = [test_accuracy, test_precision, test_recall, test_f1]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, train_scores, width, label='Train', color='skyblue')\n",
    "plt.bar(x + width/2, test_scores, width, label='Test', color='orange')\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Logistic Regression Performance Metrics')\n",
    "plt.xticks(x, metrics)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add text annotations for each bar\n",
    "for i in range(len(metrics)):\n",
    "    plt.text(i - width/2, train_scores[i] + 0.01, f'{train_scores[i]:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "    plt.text(i + width/2, test_scores[i] + 0.01, f'{test_scores[i]:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('logistic_performance_metrics.png')\n",
    "plt.show()\n",
    "\n",
    "# Visualize accuracy\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.bar(['Train', 'Test'], [train_accuracy, test_accuracy], color=['skyblue', 'orange'])\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Logistic Regression Accuracy')\n",
    "for i, v in enumerate([train_accuracy, test_accuracy]):\n",
    "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix visualization\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('logistic_confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ROC and AUC visualization\n",
    "print(\"\\nGenerating ROC and AUC visualization...\")\n",
    "\n",
    "n_classes = len(np.unique(y_test))\n",
    "# Binarize the output for multi-class ROC\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=np.arange(1, n_classes+1))\n",
    "y_score = clf.predict_proba(X_test)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'Class {i+1} (AUC = {roc_auc[i]:.2f})')\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label=f'micro-average ROC curve (AUC = {roc_auc[\"micro\"]:.2f})',\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-class ROC Curve (One-vs-Rest)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('logistic_multiclass_roc_auc.png')\n",
    "plt.close()\n",
    "print(\"Multi-class ROC and AUC visualization saved as 'logistic_multiclass_roc_auc.png'\")\n",
    "\n",
    "\n",
    "# Learning curve visualization\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    clf, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10), shuffle=True, random_state=42)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training score')\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color='g', label='Cross-validation score')\n",
    "plt.xlabel('Training Examples')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Learning Curve (Logistic Regression)')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('logistic_learning_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# Visualize decision boundary with PCA dimensionality reduction\n",
    "print(\"\\nGenerating decision boundary visualization...\")\n",
    "\n",
    "# Load activity labels\n",
    "labels = []\n",
    "with open('activity_labels.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        labels.append(line.strip().split(' ')[1])\n",
    "\n",
    "# Use a subset of test data for visualization\n",
    "sample_size = min(1000, X_test.shape[0])\n",
    "indices = np.random.choice(X_test.shape[0], sample_size, replace=False)\n",
    "X_test_sample = X_test[indices]\n",
    "y_test_sample = y_test[indices]\n",
    "\n",
    "# Apply PCA to reduce dimensions to 2D\n",
    "pca = PCA(n_components=2)\n",
    "X_test_pca = pca.fit_transform(X_test_sample)\n",
    "\n",
    "# Train a new logistic regression model on the PCA-reduced data\n",
    "# We'll use a binary classification for visualization\n",
    "# Select the most common class versus all others\n",
    "unique_classes, class_counts = np.unique(y_test_sample, return_counts=True)\n",
    "most_common_class = unique_classes[np.argmax(class_counts)]\n",
    "y_binary = (y_test_sample == most_common_class).astype(int)\n",
    "\n",
    "# Train logistic regression on 2D data\n",
    "lr_2d = LogisticRegression(max_iter=200, solver='lbfgs')\n",
    "lr_2d.fit(X_test_pca, y_binary)\n",
    "\n",
    "# Create a mesh grid for visualization\n",
    "h = 0.02  # Step size\n",
    "x_min, x_max = X_test_pca[:, 0].min() - 1, X_test_pca[:, 0].max() + 1\n",
    "y_min, y_max = X_test_pca[:, 1].min() - 1, X_test_pca[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict class probabilities for each point in the mesh\n",
    "Z = lr_2d.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.contourf(xx, yy, Z, levels=np.linspace(0, 1, 11), cmap=plt.cm.RdBu, alpha=0.8)\n",
    "plt.colorbar(label='Probability of Class 1')\n",
    "\n",
    "# Plot decision boundary contour\n",
    "plt.contour(xx, yy, Z, levels=[0.5], colors='k', linestyles='-', linewidths=2)\n",
    "\n",
    "# Plot class samples\n",
    "plt.scatter(X_test_pca[y_binary == 0, 0], X_test_pca[y_binary == 0, 1], \n",
    "           c='blue', label=f'Other Classes', s=50, alpha=0.8, edgecolors='k')\n",
    "plt.scatter(X_test_pca[y_binary == 1, 0], X_test_pca[y_binary == 1, 1], \n",
    "           c='red', label=f'Class {most_common_class} ({labels[most_common_class-1]})', s=50, alpha=0.8, edgecolors='k')\n",
    "\n",
    "plt.title('Logistic Regression Decision Boundary (PCA-Reduced Data)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('logistic_decision_boundary.png')\n",
    "plt.close()\n",
    "print(\"Logistic regression decision boundary visualization saved as 'logistic_decision_boundary.png'\")\n",
    "\n",
    "# Visualize multi-class decision boundary if possible\n",
    "print(\"\\nGenerating multi-class decision boundary visualization...\")\n",
    "\n",
    "# Train model on all classes with 2D data\n",
    "lr_multi = LogisticRegression(max_iter=200, solver='lbfgs', multi_class='multinomial')\n",
    "lr_multi.fit(X_test_pca, y_test_sample)\n",
    "\n",
    "# Create a mesh grid for visualization\n",
    "Z_multi = lr_multi.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z_multi = Z_multi.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create a custom colormap with the number of colors equal to the number of classes\n",
    "n_classes = len(unique_classes)\n",
    "colors = list(plt.cm.tab10.colors)[:n_classes]\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "# Plot the decision regions\n",
    "plt.contourf(xx, yy, Z_multi, alpha=0.3, cmap=cmap)\n",
    "\n",
    "# Plot class samples\n",
    "scatter = plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], \n",
    "                     c=y_test_sample, cmap=cmap, s=50, alpha=0.9, edgecolors='k')\n",
    "\n",
    "plt.title('Multi-class Logistic Regression Decision Boundaries (PCA-Reduced Data)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "\n",
    "# Add legend with class labels\n",
    "legend_elements = []\n",
    "for i, class_id in enumerate(unique_classes):\n",
    "    legend_elements.append(plt.Line2D([0], [0], marker='o', color='w', \n",
    "                          markerfacecolor=colors[i % len(colors)], \n",
    "                          markersize=10, label=f'Class {class_id} ({labels[class_id-1]})'))\n",
    "    \n",
    "plt.legend(handles=legend_elements, loc='best')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('logistic_multiclass_boundary.png')\n",
    "plt.close()\n",
    "print(\"Multi-class logistic regression boundaries visualization saved as 'logistic_multiclass_boundary.png'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be83a99",
   "metadata": {},
   "source": [
    "\n",
    "1. **Data Loading & Preparation**  \n",
    "   - Read training and test features (`X_train`, `X_test`) and labels (`y_train`, `y_test`) from text files.  \n",
    "   - No additional preprocessing is shown, assuming data is ready for model fitting.\n",
    "\n",
    "2. **Model Training**  \n",
    "   - Instantiate a multinomial **Logistic Regression** classifier (`lbfgs` solver, `max_iter=200`).  \n",
    "   - Fit the model on the training set (`X_train`, `y_train`).\n",
    "\n",
    "3. **Performance Evaluation**  \n",
    "   - Compute **accuracy**, **precision**, **recall**, and **F1-score** on both train and test sets.  \n",
    "   - Display a **classification report** and **confusion matrix** to inspect per-class results.  \n",
    "   - Plot a bar chart comparing train vs. test metrics for quick visual assessment.\n",
    "\n",
    "4. **ROC & AUC (Multi-class)**  \n",
    "   - Binarize labels and compute **one-vs-rest** ROC curves for each class.  \n",
    "   - Calculate area under the curve (AUC) and plot micro-average ROC.\n",
    "\n",
    "5. **Learning Curve**  \n",
    "   - Use `learning_curve` to measure training and cross-validation accuracy as a function of training set size.  \n",
    "   - Visualize how model performance scales with more data.\n",
    "\n",
    "6. **Decision Boundary Visualization**  \n",
    "   - Apply **PCA** to project high-dimensional test samples into 2D.  \n",
    "   - Train a binary logistic model on the two principal components to show a single-class decision boundary.  \n",
    "   - Train a multinomial logistic model on the same 2D data to display multi-class decision regions.  \n",
    "   - Overlay sample points and contour plots to illustrate how the classifier separates classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be1ea2",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b45bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "print(\"loading data...\")\n",
    "X_train = np.loadtxt('train/X_train.txt')\n",
    "X_test = np.loadtxt('test/X_test.txt')\n",
    "\n",
    "y_train = np.loadtxt('train/y_train.txt').astype(int)\n",
    "y_test = np.loadtxt('test/y_test.txt').astype(int)\n",
    "\n",
    "# Load feature names\n",
    "labels = []\n",
    "with open('activity_labels.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        labels.append(line.strip().split(' ')[1])\n",
    "\n",
    "print(f\"Data loading completed: {X_train.shape[0]} training samples, {X_test.shape[0]} test samples\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")\n",
    "print(f\"Activity classes: {len(set(y_train))}\")\n",
    "\n",
    "# Training basic SVM model\n",
    "print(\"Training basic SVM model...\")\n",
    "svm_model = SVC(kernel='rbf', gamma='scale', C=1.0)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluating basic model\n",
    "# Calculate performance metrics for training set\n",
    "y_pred_train = svm_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "train_precision = precision_score(y_train, y_pred_train, average='weighted')\n",
    "train_recall = recall_score(y_train, y_pred_train, average='weighted')\n",
    "train_f1 = f1_score(y_train, y_pred_train, average='weighted')\n",
    "\n",
    "# Calculate performance metrics for test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "test_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "test_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print all metrics\n",
    "print(f\"SVM Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"SVM Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"SVM Train Precision: {train_precision:.4f}\")\n",
    "print(f\"SVM Test Precision: {test_precision:.4f}\")\n",
    "print(f\"SVM Train Recall: {train_recall:.4f}\")\n",
    "print(f\"SVM Test Recall: {test_recall:.4f}\")\n",
    "print(f\"SVM Train F1 Score: {train_f1:.4f}\")\n",
    "print(f\"SVM Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Using grid search for hyperparameter tuning\n",
    "print(\"\\nPerforming hyperparameter tuning...\")\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.01],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "# Using a subset of training data for hyperparameter search to reduce computation time\n",
    "sample_size = min(5000, X_train.shape[0])\n",
    "indices = np.random.choice(X_train.shape[0], sample_size, replace=False)\n",
    "X_sample = X_train[indices]\n",
    "y_sample = y_train[indices]\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=3, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_sample, y_sample)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Train final model using best parameters\n",
    "final_model = SVC(**grid_search.best_params_)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate final model on test set\n",
    "# Get predictions for both training and test sets\n",
    "y_pred_final_train = final_model.predict(X_train)\n",
    "y_pred_final = final_model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics for training set\n",
    "final_train_accuracy = accuracy_score(y_train, y_pred_final_train)\n",
    "final_train_precision = precision_score(y_train, y_pred_final_train, average='weighted')\n",
    "final_train_recall = recall_score(y_train, y_pred_final_train, average='weighted')\n",
    "final_train_f1 = f1_score(y_train, y_pred_final_train, average='weighted')\n",
    "\n",
    "# Calculate performance metrics for test set\n",
    "final_test_accuracy = accuracy_score(y_test, y_pred_final)\n",
    "final_test_precision = precision_score(y_test, y_pred_final, average='weighted')\n",
    "final_test_recall = recall_score(y_test, y_pred_final, average='weighted')\n",
    "final_test_f1 = f1_score(y_test, y_pred_final, average='weighted')\n",
    "\n",
    "# Print results for optimized model\n",
    "print(\"\\nOptimized SVM Model Performance Metrics:\")\n",
    "print(f\"Optimized SVM Train Accuracy: {final_train_accuracy:.4f}\")\n",
    "print(f\"Optimized SVM Test Accuracy: {final_test_accuracy:.4f}\")\n",
    "print(f\"Optimized SVM Train Precision: {final_train_precision:.4f}\")\n",
    "print(f\"Optimized SVM Test Precision: {final_test_precision:.4f}\")\n",
    "print(f\"Optimized SVM Train Recall: {final_train_recall:.4f}\")\n",
    "print(f\"Optimized SVM Test Recall: {final_test_recall:.4f}\")\n",
    "print(f\"Optimized SVM Train F1 Score: {final_train_f1:.4f}\")\n",
    "print(f\"Optimized SVM Test F1 Score: {final_test_f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification report for each activity after optimization:\")\n",
    "print(classification_report(y_test, y_pred_final, target_names=labels))\n",
    "\n",
    "\n",
    "# Visualization Section\n",
    "\n",
    "print(\"\\nGenerating visualizations...\")\n",
    "\n",
    "# Visualize performance metrics\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "train_scores = [final_train_accuracy, final_train_precision, final_train_recall, final_train_f1]\n",
    "test_scores = [final_test_accuracy, final_test_precision, final_test_recall, final_test_f1]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, train_scores, width, label='Train', color='skyblue')\n",
    "plt.bar(x + width/2, test_scores, width, label='Test', color='orange')\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Score')\n",
    "plt.title('SVM Performance Metrics')\n",
    "plt.xticks(x, metrics)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i in range(len(metrics)):\n",
    "    plt.text(i - width/2, train_scores[i] + 0.01, f'{train_scores[i]:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "    plt.text(i + width/2, test_scores[i] + 0.01, f'{test_scores[i]:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('svm_performance_metrics.png')\n",
    "plt.close()\n",
    "print(\"Performance metrics visualization saved as 'svm_performance_metrics.png'\")\n",
    "\n",
    "# 1. Confusion Matrix Visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_final), annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix - SVM Classification')\n",
    "plt.tight_layout()\n",
    "plt.savefig('svm_confusion_matrix.png')\n",
    "plt.close()\n",
    "print(\"Confusion matrix visualization saved as 'svm_confusion_matrix.png'\")\n",
    "\n",
    "# 1.5 ROC and AUC Visualization\n",
    "print(\"\\nGenerating ROC and AUC visualization...\")\n",
    "n_classes = len(np.unique(y_test))\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=np.arange(1, n_classes+1))\n",
    "y_score = final_model.decision_function(X_test)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'Class {i+1} (AUC = {roc_auc[i]:.2f})')\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label=f'micro-average ROC curve (AUC = {roc_auc[\"micro\"]:.2f})',\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-class ROC Curve (One-vs-Rest, SVM)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('svm_multiclass_roc_auc.png')\n",
    "plt.close()\n",
    "print(\"Multi-class ROC and AUC visualization saved as 'svm_multiclass_roc_auc.png'\")\n",
    "\n",
    "\n",
    "# 2. Learning Curves - Training and Validation Performance with varying training set sizes\n",
    "print(\"\\nGenerating learning curves (this may take a few minutes)...\")\n",
    "train_sizes, train_scores, valid_scores = learning_curve(\n",
    "    estimator=final_model, X=X_sample, y=y_sample, \n",
    "    train_sizes=np.linspace(0.1, 1.0, 5), cv=3, n_jobs=-1\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, np.mean(train_scores, axis=1), 'o-', color='blue', label='Training Accuracy')\n",
    "plt.plot(train_sizes, np.mean(valid_scores, axis=1), 'o-', color='red', label='Validation Accuracy')\n",
    "plt.title('Learning Curves - SVM Model')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.savefig('svm_learning_curve.png')\n",
    "plt.close()\n",
    "print(\"Learning curve visualization saved as 'svm_learning_curve.png'\")\n",
    "\n",
    "# 3. Validation Curve - Model Performance vs. Hyperparameter (C parameter)\n",
    "print(\"\\nGenerating validation curve for C parameter...\")\n",
    "c_range = np.logspace(-3, 3, 5)\n",
    "train_scores, valid_scores = validation_curve(\n",
    "    estimator=SVC(kernel=final_model.kernel, gamma=final_model.gamma), \n",
    "    X=X_sample, y=y_sample, param_name='C', param_range=c_range, cv=3, n_jobs=-1\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(c_range, np.mean(train_scores, axis=1), 'o-', color='blue', label='Training Accuracy')\n",
    "plt.semilogx(c_range, np.mean(valid_scores, axis=1), 'o-', color='red', label='Validation Accuracy')\n",
    "plt.title('Validation Curve - C Parameter (SVM)')\n",
    "plt.xlabel('C Parameter (log scale)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.savefig('svm_validation_curve.png')\n",
    "plt.close()\n",
    "print(\"Validation curve visualization saved as 'svm_validation_curve.png'\")\n",
    "\n",
    "# 4. Dimensionality Reduction Visualization\n",
    "print(\"\\nPerforming dimensionality reduction for visualization...\")\n",
    "\n",
    "# 4.1 Using PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_test_pca = pca.fit_transform(X_test)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=y_pred_final, cmap='viridis', alpha=0.8, edgecolors='w', s=50)\n",
    "plt.title('PCA Visualization of SVM Classification Results')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar(label='Activity Class')\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=labels, title=\"Activities\", loc=\"best\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig('svm_pca_visualization.png')\n",
    "plt.close()\n",
    "print(\"PCA visualization saved as 'svm_pca_visualization.png'\")\n",
    "\n",
    "# 4.2 Using t-SNE for better cluster visualization (takes longer but often gives better separation)\n",
    "print(\"\\nPerforming t-SNE dimensionality reduction (this may take a few minutes)...\")\n",
    "# Using a subset of test data for t-SNE to speed up computation\n",
    "sample_size_tsne = min(1000, X_test.shape[0])\n",
    "indices_tsne = np.random.choice(X_test.shape[0], sample_size_tsne, replace=False)\n",
    "X_test_sample = X_test[indices_tsne]\n",
    "y_test_sample = y_test[indices_tsne]\n",
    "y_pred_sample = y_pred_final[indices_tsne]\n",
    "\n",
    "# Perform t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=300, random_state=42)\n",
    "X_test_tsne = tsne.fit_transform(X_test_sample)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = plt.scatter(X_test_tsne[:, 0], X_test_tsne[:, 1], c=y_pred_sample, cmap='viridis', alpha=0.8, edgecolors='w', s=50)\n",
    "plt.title('t-SNE Visualization of SVM Classification Results')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.colorbar(label='Activity Class')\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=labels, title=\"Activities\", loc=\"best\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig('svm_tsne_visualization.png')\n",
    "plt.close()\n",
    "print(\"t-SNE visualization saved as 'svm_tsne_visualization.png'\")\n",
    "\n",
    "# 5. Decision Boundary Visualization (using PCA-reduced data)\n",
    "print(\"\\nGenerating SVM decision boundary visualization...\")\n",
    "\n",
    "# Use PCA to reduce to 2D for visualization (using a smaller subset for speed)\n",
    "sample_size_db = min(1000, X_test.shape[0])\n",
    "indices_db = np.random.choice(X_test.shape[0], sample_size_db, replace=False)\n",
    "X_test_subset = X_test[indices_db]\n",
    "y_test_subset = y_test[indices_db]\n",
    "\n",
    "# Apply PCA\n",
    "pca_boundary = PCA(n_components=2)\n",
    "X_test_pca_boundary = pca_boundary.fit_transform(X_test_subset)\n",
    "\n",
    "# Train a new SVM model on the PCA-reduced data\n",
    "# Since we have multiple classes, we'll visualize a binary version for demonstration\n",
    "# Let's choose the most common class vs all others\n",
    "unique_classes, class_counts = np.unique(y_test_subset, return_counts=True)\n",
    "most_common_class = unique_classes[np.argmax(class_counts)]\n",
    "y_binary = (y_test_subset == most_common_class).astype(int)\n",
    "\n",
    "# Train SVM on 2D data\n",
    "svm_2d = SVC(kernel=final_model.kernel, C=final_model.C, gamma=final_model.gamma)\n",
    "svm_2d.fit(X_test_pca_boundary, y_binary)\n",
    "\n",
    "# Create a mesh grid for the decision boundary\n",
    "h = 0.02  # Step size in the mesh\n",
    "x_min, x_max = X_test_pca_boundary[:, 0].min() - 1, X_test_pca_boundary[:, 0].max() + 1\n",
    "y_min, y_max = X_test_pca_boundary[:, 1].min() - 1, X_test_pca_boundary[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict class for each point in the mesh\n",
    "Z = svm_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)\n",
    "\n",
    "# Plot class samples\n",
    "plt.scatter(X_test_pca_boundary[y_binary == 0, 0], X_test_pca_boundary[y_binary == 0, 1], \n",
    "           c='blue', label=f'Other Classes', s=50, alpha=0.8, edgecolors='k')\n",
    "plt.scatter(X_test_pca_boundary[y_binary == 1, 0], X_test_pca_boundary[y_binary == 1, 1], \n",
    "           c='red', label=f'Class {most_common_class} ({labels[most_common_class-1]})', s=50, alpha=0.8, edgecolors='k')\n",
    "\n",
    "# Plot support vectors\n",
    "plt.scatter(svm_2d.support_vectors_[:, 0], svm_2d.support_vectors_[:, 1], \n",
    "           s=100, facecolors='none', edgecolors='green', label='Support Vectors')\n",
    "\n",
    "plt.title('SVM Decision Boundary (PCA-Reduced Data)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig('svm_decision_boundary.png')\n",
    "plt.close()\n",
    "print(\"SVM decision boundary visualization saved as 'svm_decision_boundary.png'\")\n",
    "\n",
    "print(\"\\nAll visualizations completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f46b1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **Data Loading**  \n",
    "   - Read training and test feature matrices and labels from text files.  \n",
    "   - Load activity names for later visualization.\n",
    "\n",
    "2. **Baseline SVM Training**  \n",
    "   - Fit an RBF‐kernel SVM (`C=1.0`, `gamma='scale'`) on the full training set.  \n",
    "   - Evaluate accuracy, precision, recall, F1 on both train and test splits.\n",
    "\n",
    "3. **Hyperparameter Tuning**  \n",
    "   - Sample a subset of training data (≤5000 samples).  \n",
    "   - Run `GridSearchCV` over `C`, `gamma`, and `kernel` to find the best SVM configuration.\n",
    "\n",
    "4. **Final Model & Evaluation**  \n",
    "   - Retrain SVM with optimal parameters on the entire training set.  \n",
    "   - Compute detailed metrics and print a per‐class classification report.\n",
    "\n",
    "5. **Visualization Suite**  \n",
    "   - **Performance Metrics:** Bar charts comparing train vs. test scores.  \n",
    "   - **Confusion Matrix:** Heatmap of true vs. predicted classes.  \n",
    "   - **ROC/AUC:** One‐vs‐rest ROC curves and micro‐average AUC.  \n",
    "   - **Learning & Validation Curves:** Show impact of sample size and hyperparameter `C`.  \n",
    "   - **Dimensionality Reduction:**  \n",
    "     - PCA and t-SNE scatter plots colored by predicted labels.  \n",
    "     - 2D decision boundary plots (binary demo with PCA).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358c211e",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb777e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建图像输出文件夹\n",
    "os.makedirs(\"figures\", exist_ok=True)\n",
    "\n",
    "# ---------------- 数据加载与映射 ---------------- #\n",
    "features = pd.read_csv(\"features.txt\", sep=r'\\s+', header=None)\n",
    "feature_names = features[1].values\n",
    "\n",
    "activity_labels = pd.read_csv(\"activity_labels.txt\", sep=r'\\s+', header=None, index_col=0)\n",
    "activity_map = activity_labels[1].to_dict()\n",
    "\n",
    "X_train = pd.read_csv(\"train/X_train.txt\", sep=r'\\s+', header=None)\n",
    "y_train = pd.read_csv(\"train/y_train.txt\", header=None)[0].map(activity_map)\n",
    "\n",
    "X_test = pd.read_csv(\"test/X_test.txt\", sep=r'\\s+', header=None)\n",
    "y_test = pd.read_csv(\"test/y_test.txt\", header=None)[0].map(activity_map)\n",
    "\n",
    "X_train.columns = feature_names\n",
    "X_test.columns = feature_names\n",
    "\n",
    "# ---------------- 标准化 ---------------- #\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=feature_names)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=feature_names)\n",
    "\n",
    "# ---------------- 网格搜索调参 ---------------- #\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ---------------- 最佳模型评估 ---------------- #\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ---------------- 混淆矩阵 ---------------- #\n",
    "cm = confusion_matrix(y_test, y_pred, labels=best_rf.classes_)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=best_rf.classes_,\n",
    "            yticklabels=best_rf.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Tuned Random Forest)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/rf_confusion_matrix.png\")\n",
    "plt.close()\n",
    "\n",
    "# ---------------- 多类别 ROC 曲线 ---------------- #\n",
    "class_names = sorted(y_train.unique())\n",
    "y_test_bin = label_binarize(y_test, classes=class_names)\n",
    "y_score = best_rf.predict_proba(X_test_scaled)\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Macro-average\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "mean_tpr /= n_classes\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# 绘图\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"{class_names[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label=f\"Macro-average (AUC = {roc_auc['macro']:.2f})\",\n",
    "         color='navy', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve (Random Forest)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/rf_roc_auc.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c4c76",
   "metadata": {},
   "source": [
    "\n",
    "1. **Data Loading & Label Mapping**\n",
    "   - Read feature names and activity labels.\n",
    "   - Load training and test sets (`X_train`, `X_test`) and map integer labels to activity names (`y_train`, `y_test`).\n",
    "\n",
    "2. **Feature Standardization**\n",
    "   - Apply `StandardScaler` to zero–mean, unit-variance normalize all features.\n",
    "\n",
    "3. **Hyperparameter Tuning**\n",
    "   - Define a grid over:\n",
    "     - Number of trees (`n_estimators`: 100, 200)\n",
    "     - Maximum tree depth (`max_depth`: 10, 20, None)\n",
    "     - Minimum samples to split (`min_samples_split`: 2, 5)\n",
    "     - Feature subset strategy (`max_features`: “sqrt”, “log2”)\n",
    "   - Run 3-fold `GridSearchCV` (accuracy scoring) to find the best Random Forest settings.\n",
    "\n",
    "4. **Model Evaluation**\n",
    "   - Fit the best estimator on the scaled training data.\n",
    "   - Report:\n",
    "     - **Best CV Accuracy** and parameter combination.\n",
    "     - **Test Accuracy** and detailed **classification report** (precision, recall, F1).\n",
    "\n",
    "5. **Results Visualization**\n",
    "   - **Confusion Matrix**: heatmap of true vs. predicted labels.\n",
    "   - **Multi-class ROC Curves**:\n",
    "     - Binarize labels.\n",
    "     - Compute per-class and macro-average ROC AUC.\n",
    "     - Plot all ROC curves with AUC annotations.\n",
    "\n",
    "All figures are saved under the `figures/` directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9617a2",
   "metadata": {},
   "source": [
    "## Open exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8421e73f",
   "metadata": {},
   "source": [
    "**Ridge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c5496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== 1. 数据加载 ======================\n",
    "features = pd.read_csv(\"features.txt\", sep=r'\\s+', header=None)\n",
    "feature_names = features[1].values\n",
    "\n",
    "activity_labels = pd.read_csv(\"activity_labels.txt\", sep=r'\\s+', header=None, index_col=0)\n",
    "activity_map = activity_labels[1].to_dict()\n",
    "\n",
    "X_train = pd.read_csv(\"train/X_train.txt\", sep=r'\\s+', header=None)\n",
    "y_train = pd.read_csv(\"train/y_train.txt\", header=None)[0].map(activity_map)\n",
    "\n",
    "X_test = pd.read_csv(\"test/X_test.txt\", sep=r'\\s+', header=None)\n",
    "y_test = pd.read_csv(\"test/y_test.txt\", header=None)[0].map(activity_map)\n",
    "\n",
    "X_train.columns = feature_names\n",
    "X_test.columns = feature_names\n",
    "\n",
    "# ====================== 2. 特征标准化 ======================\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ====================== 3. 超参数网格搜索 ======================\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "ridge_clf = RidgeClassifier()\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    ridge_clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ====================== 4. 最优参数和验证得分 ======================\n",
    "print(\"Best alpha:\", grid.best_params_['alpha'])\n",
    "print(\"Best Cross-Validated Accuracy:\", grid.best_score_)\n",
    "\n",
    "# ====================== 5. 在测试集上评估最优模型 ======================\n",
    "best_ridge = grid.best_estimator_\n",
    "y_train_pred = best_ridge.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "\n",
    "y_pred = best_ridge.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nTest Accuracy (RidgeClassifier):\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ====================== 6. 混淆矩阵可视化 ======================\n",
    "cm = confusion_matrix(y_test, y_pred, labels=best_ridge.classes_)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=best_ridge.classes_,\n",
    "            yticklabels=best_ridge.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Ridge Classifier Confusion Matrix (alpha tuned)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7591ccb",
   "metadata": {},
   "source": [
    "1. **Data Loading & Label Mapping**  \n",
    "   - Read feature names and activity labels.  \n",
    "   - Load training and test feature matrices (`X_train`, `X_test`) and map integer labels to activity names (`y_train`, `y_test`).\n",
    "\n",
    "2. **Feature Standardization**  \n",
    "   - Apply `StandardScaler` to normalize features to zero mean and unit variance.\n",
    "\n",
    "3. **Hyperparameter Grid Search**  \n",
    "   - Define a grid over regularization strengths (`alpha` ∈ {0.01, 0.1, 1, 10, 100}).  \n",
    "   - Use 3-fold `GridSearchCV` (accuracy scoring) to find the best `alpha` for `RidgeClassifier`.\n",
    "\n",
    "4. **Model Evaluation**  \n",
    "   - Report the best `alpha` and cross-validated accuracy.  \n",
    "   - Retrain on the full training set and compute accuracy on both training and test sets.  \n",
    "   - Print a detailed classification report (precision, recall, F1-score).\n",
    "\n",
    "5. **Results Visualization**  \n",
    "   - Plot a confusion matrix heatmap for the test predictions to illustrate per-class performance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c124623",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a79a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== 1. 数据加载 ======================\n",
    "features = pd.read_csv(\"features.txt\", sep=r'\\s+', header=None)\n",
    "feature_names = features[1].values\n",
    "\n",
    "activity_labels = pd.read_csv(\"activity_labels.txt\", sep=r'\\s+', header=None, index_col=0)\n",
    "activity_map = activity_labels[1].to_dict()\n",
    "\n",
    "X_train = pd.read_csv(\"train/X_train.txt\", sep=r'\\s+', header=None)\n",
    "y_train = pd.read_csv(\"train/y_train.txt\", header=None)[0].map(activity_map)\n",
    "\n",
    "X_test = pd.read_csv(\"test/X_test.txt\", sep=r'\\s+', header=None)\n",
    "y_test = pd.read_csv(\"test/y_test.txt\", header=None)[0].map(activity_map)\n",
    "\n",
    "X_train.columns = feature_names\n",
    "X_test.columns = feature_names\n",
    "\n",
    "# ====================== 2. 特征标准化 ======================\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ====================== 3. 构建 Pipeline ======================\n",
    "pipe = Pipeline([\n",
    "    ('select', SelectKBest(score_func=f_classif)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# ====================== 4. 参数搜索范围 ======================\n",
    "param_grid = {\n",
    "    'select__k': [50, 100, 150, 200, 300],\n",
    "    'knn__n_neighbors': [3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "# ====================== 5. 网格搜索 GridSearchCV ======================\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ====================== 6. 输出最优参数 ======================\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best Cross-Validated Accuracy:\", grid.best_score_)\n",
    "\n",
    "# ====================== 7. 测试集评估 ======================\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nTest Accuracy with Best KNN Model:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ====================== 8. 混淆矩阵可视化 ======================\n",
    "cm = confusion_matrix(y_test, y_pred, labels=best_model.named_steps['knn'].classes_)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=best_model.named_steps['knn'].classes_,\n",
    "            yticklabels=best_model.named_steps['knn'].classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"KNN Confusion Matrix (GridSearchCV Optimized)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d04ab1",
   "metadata": {},
   "source": [
    "1. **Data Loading & Label Mapping**  \n",
    "   - Read feature names and activity labels.  \n",
    "   - Load training/testing feature matrices and map integer labels to activity names.\n",
    "\n",
    "2. **Feature Scaling**  \n",
    "   - Apply `StandardScaler` to normalize all features to zero mean and unit variance.\n",
    "\n",
    "3. **Pipeline Construction**  \n",
    "   - Chain `SelectKBest(f_classif)` for univariate feature selection and `KNeighborsClassifier` for classification.\n",
    "\n",
    "4. **Hyperparameter Grid**  \n",
    "   - Tune number of features (`k` ∈ [50,100,150,200,300]) and KNN neighbors (`n_neighbors` ∈ [3,5,7,9]) via 3-fold `GridSearchCV`.\n",
    "\n",
    "5. **Model Training & Selection**  \n",
    "   - Fit the pipeline on scaled training data, select the best parameter combination by accuracy.\n",
    "\n",
    "6. **Evaluation**  \n",
    "   - Report cross-validated and test accuracy, print a detailed classification report.\n",
    "\n",
    "7. **Results Visualization**  \n",
    "   - Plot a confusion matrix heatmap of test predictions to inspect per-class performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "har_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
